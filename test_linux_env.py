#!/usr/bin/env python3
"""
æµ‹è¯•Linuxç¯å¢ƒæ˜¯å¦å‡†å¤‡å°±ç»ª
"""

import sys
import torch
import json
import os
from PIL import Image

def test_environment():
    print("ğŸ§ª æµ‹è¯•Linuxç¯å¢ƒ...")
    
    # 1. æ£€æŸ¥Pythonç‰ˆæœ¬
    print(f"ğŸ Pythonç‰ˆæœ¬: {sys.version}")
    
    # 2. æ£€æŸ¥PyTorchå’ŒCUDA
    print(f"ğŸ”¥ PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"ğŸš€ CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"ğŸ¯ CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"ğŸ’¾ GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            print(f"  GPU {i}: {props.name} ({props.total_memory / 1e9:.1f}GB)")
    
    # 3. æ£€æŸ¥å…³é”®ä¾èµ–
    try:
        import transformers
        print(f"ğŸ¤— Transformersç‰ˆæœ¬: {transformers.__version__}")
    except ImportError:
        print("âŒ Transformersæœªå®‰è£…")
    
    try:
        import peft
        print(f"ğŸ”§ PEFTç‰ˆæœ¬: {peft.__version__}")
    except ImportError:
        print("âŒ PEFTæœªå®‰è£…")
    
    try:
        import deepspeed
        print(f"âš¡ DeepSpeedç‰ˆæœ¬: {deepspeed.__version__}")
    except ImportError:
        print("âŒ DeepSpeedæœªå®‰è£…")
    
    try:
        import bitsandbytes
        print(f"ğŸ”¢ BitsAndBytesç‰ˆæœ¬: {bitsandbytes.__version__}")
    except ImportError:
        print("âŒ BitsAndBytesæœªå®‰è£…")
    
    # 4. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = "./models/ShowUI-2B"
    if os.path.exists(model_path):
        print(f"âœ… æ¨¡å‹æ–‡ä»¶å­˜åœ¨: {model_path}")
        files = os.listdir(model_path)
        print(f"  æ–‡ä»¶æ•°é‡: {len(files)}")
        key_files = ['config.json', 'model.safetensors.index.json']
        for key_file in key_files:
            if key_file in files:
                print(f"  âœ… {key_file}")
            else:
                print(f"  âŒ {key_file}")
    else:
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    # 5. æ£€æŸ¥æ•°æ®æ–‡ä»¶
    data_path = "./data/my_dataset/metadata.json"
    if os.path.exists(data_path):
        print(f"âœ… æ•°æ®æ–‡ä»¶å­˜åœ¨: {data_path}")
        with open(data_path, 'r') as f:
            data = json.load(f)
        print(f"  æ•°æ®æ¡æ•°: {len(data)}")
        
        # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶
        img_dir = "./data/my_dataset/images"
        if os.path.exists(img_dir):
            img_files = os.listdir(img_dir)
            print(f"  å›¾ç‰‡æ–‡ä»¶æ•°é‡: {len(img_files)}")
        else:
            print(f"  âŒ å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {img_dir}")
    else:
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
    
    # 6. æµ‹è¯•GPUå†…å­˜
    if torch.cuda.is_available():
        print("\nğŸ’¾ æµ‹è¯•GPUå†…å­˜...")
        device = torch.device("cuda:0")
        
        # åˆ†é…ä¸€äº›å†…å­˜æµ‹è¯•
        try:
            x = torch.randn(1000, 1000, device=device)
            y = torch.randn(1000, 1000, device=device)
            z = torch.matmul(x, y)
            print("âœ… GPUè®¡ç®—æµ‹è¯•é€šè¿‡")
            
            # æ˜¾ç¤ºå†…å­˜ä½¿ç”¨
            allocated = torch.cuda.memory_allocated(0) / 1e9
            cached = torch.cuda.memory_reserved(0) / 1e9
            print(f"  å·²åˆ†é…å†…å­˜: {allocated:.2f}GB")
            print(f"  ç¼“å­˜å†…å­˜: {cached:.2f}GB")
            
            # æ¸…ç†
            del x, y, z
            torch.cuda.empty_cache()
            
        except Exception as e:
            print(f"âŒ GPUæµ‹è¯•å¤±è´¥: {e}")
    
    print("\nğŸ‰ ç¯å¢ƒæ£€æŸ¥å®Œæˆ!")

if __name__ == "__main__":
    test_environment()
