# ShowUI-2B é˜¿é‡Œäº‘Linuxå¾®è°ƒæŒ‡å—

## ğŸ–¥ï¸ ç¯å¢ƒè¦æ±‚

- **GPU**: NVIDIA A10 (24GBæ˜¾å­˜)
- **CPU**: 8æ ¸
- **å†…å­˜**: 30GB
- **ç³»ç»Ÿ**: Linux (Ubuntu/CentOS)
- **CUDA**: 11.8+
- **Python**: 3.8+

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <your-repo>
cd showui-finetune

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv showui_env
source showui_env/bin/activate

# 3. å®‰è£…ä¾èµ–
pip install -r requirements_linux.txt

# 4. å®‰è£…DeepSpeedå’Œä¼˜åŒ–åº“
pip install deepspeed
pip install flash-attn --no-build-isolation  # å¯é€‰ï¼Œç¼–è¯‘æ—¶é—´è¾ƒé•¿
```

### 2. æ¨¡å‹å‡†å¤‡

ç¡®ä¿ShowUI-2Bæ¨¡å‹åœ¨ `./models/ShowUI-2B/` ç›®å½•ä¸‹ï¼š

```bash
ls ./models/ShowUI-2B/
# åº”è¯¥åŒ…å«ï¼š
# - config.json
# - model.safetensors.index.json
# - model-*.safetensors
# - tokenizer.json
# - ç­‰æ–‡ä»¶
```

### 3. æ•°æ®å‡†å¤‡

ç¡®ä¿è®­ç»ƒæ•°æ®åœ¨ `./data/my_dataset/` ç›®å½•ä¸‹ï¼š

```bash
ls ./data/my_dataset/
# åº”è¯¥åŒ…å«ï¼š
# - metadata.json  (è®­ç»ƒæ•°æ®æ ‡æ³¨)
# - images/        (å›¾ç‰‡æ–‡ä»¶å¤¹)
```

### 4. ç¯å¢ƒæµ‹è¯•

```bash
python test_linux_env.py
```

### 5. å¼€å§‹è®­ç»ƒ

```bash
# ä¸ä½¿ç”¨wandb
./run_linux_training.sh

# ä½¿ç”¨wandbç›‘æ§
./run_linux_training.sh your_wandb_key
```

## âš™ï¸ é…ç½®è¯´æ˜

### è®­ç»ƒå‚æ•°

ä¸»è¦è®­ç»ƒå‚æ•°åœ¨ `run_linux_training.sh` ä¸­ï¼š

```bash
--model_id showlab/ShowUI-2B          # æ¨¡å‹ID
--local_weight_dir ./models           # æœ¬åœ°æ¨¡å‹è·¯å¾„
--precision bf16                      # ç²¾åº¦ (bf16/fp16/fp32)
--use_qlora                          # ä½¿ç”¨QLoRA
--load_in_4bit                       # 4bité‡åŒ–
--use_deepspeed                      # ä½¿ç”¨DeepSpeed
--lora_r 16                          # LoRA rank
--lora_alpha 32                      # LoRA alpha
--batch_size 1                       # æ‰¹æ¬¡å¤§å°
--grad_accumulation_steps 8          # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
--lr 2e-4                           # å­¦ä¹ ç‡
--epochs 3                          # è®­ç»ƒè½®æ•°
--max_steps 1000                    # æœ€å¤§æ­¥æ•°
```

### DeepSpeedé…ç½®

DeepSpeedé…ç½®åœ¨ `ds_config.json` ä¸­ï¼š

- **ZeRO Stage 2**: ä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡
- **BF16**: æ··åˆç²¾åº¦è®­ç»ƒ
- **æ¢¯åº¦è£å‰ª**: é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
- **è‡ªåŠ¨æ‰¹æ¬¡å¤§å°**: æ ¹æ®GPUå†…å­˜è‡ªåŠ¨è°ƒæ•´

## ğŸ“Š ç›‘æ§è®­ç»ƒ

### 1. ç»ˆç«¯è¾“å‡º

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ˜¾ç¤ºï¼š
- æŸå¤±å€¼å˜åŒ–
- è®­ç»ƒæ­¥æ•°
- GPUå†…å­˜ä½¿ç”¨
- è®­ç»ƒé€Ÿåº¦

### 2. WandBç›‘æ§

å¦‚æœæä¾›äº†wandb_keyï¼Œå¯ä»¥åœ¨WandBç½‘ç«™æŸ¥çœ‹ï¼š
- æŸå¤±æ›²çº¿
- å­¦ä¹ ç‡å˜åŒ–
- ç³»ç»Ÿèµ„æºä½¿ç”¨

### 3. æ—¥å¿—æ–‡ä»¶

è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨ `./logs/showui_linux_YYYYMMDD_HHMMSS/`

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   ```bash
   # å‡å°‘æ‰¹æ¬¡å¤§å°
   --batch_size 1
   --grad_accumulation_steps 4
   ```

2. **DeepSpeedåˆå§‹åŒ–å¤±è´¥**
   ```bash
   # æ£€æŸ¥CUDAç¯å¢ƒ
   nvidia-smi
   nvcc --version
   ```

3. **æ¨¡å‹åŠ è½½å¤±è´¥**
   ```bash
   # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
   ls -la ./models/ShowUI-2B/
   ```

4. **ä¾èµ–å®‰è£…å¤±è´¥**
   ```bash
   # ä½¿ç”¨å›½å†…é•œåƒ
   pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements_linux.txt
   ```

### æ€§èƒ½ä¼˜åŒ–

1. **å¯ç”¨Flash Attention**
   ```bash
   pip install flash-attn --no-build-isolation
   ```

2. **è°ƒæ•´æ‰¹æ¬¡å¤§å°**
   - A10 24GB: batch_size=1, grad_accumulation_steps=8
   - æ›´å¤§GPU: å¯ä»¥å¢åŠ batch_size

3. **ä½¿ç”¨æ··åˆç²¾åº¦**
   ```bash
   --precision bf16  # æ¨è
   --precision fp16  # å¤‡é€‰
   ```

## ğŸ“ˆ è®­ç»ƒç»“æœ

è®­ç»ƒå®Œæˆåï¼š

1. **æ¨¡å‹æƒé‡**: `./logs/showui_linux_YYYYMMDD_HHMMSS/`
2. **LoRAé€‚é…å™¨**: `adapter_model.safetensors`
3. **é…ç½®æ–‡ä»¶**: `adapter_config.json`

## ğŸ¯ ä¸‹ä¸€æ­¥

1. **æ¨¡å‹æ¨ç†**: ä½¿ç”¨è®­ç»ƒå¥½çš„LoRAæƒé‡è¿›è¡Œæ¨ç†
2. **æ•ˆæœè¯„ä¼°**: åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
3. **å‚æ•°è°ƒä¼˜**: æ ¹æ®ç»“æœè°ƒæ•´è¶…å‚æ•°
4. **æ•°æ®æ‰©å……**: æ·»åŠ æ›´å¤šè®­ç»ƒæ•°æ®

## ğŸ“ æ”¯æŒ

å¦‚é‡é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. GPUé©±åŠ¨å’ŒCUDAç‰ˆæœ¬
2. Pythonç¯å¢ƒå’Œä¾èµ–ç‰ˆæœ¬
3. æ¨¡å‹å’Œæ•°æ®æ–‡ä»¶å®Œæ•´æ€§
4. ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
