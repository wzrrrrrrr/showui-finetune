#!/bin/bash

# ShowUI-2B å¾®è°ƒè®­ç»ƒè„šæœ¬ - é€‚ç”¨äºé˜¿é‡Œäº‘A10 GPU
# ä½¿ç”¨æ–¹æ³•: ./run_training.sh

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# ç”Ÿæˆå®éªŒID
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
EXP_ID="showui_2b_finetune_${TIMESTAMP}"

echo "ğŸš€ å¼€å§‹ShowUI-2Bå¾®è°ƒè®­ç»ƒ..."
echo "ğŸ“… å®éªŒID: ${EXP_ID}"

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
echo "ğŸ æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ..."
source showui_env/bin/activate

# æ£€æŸ¥GPUçŠ¶æ€
echo "ğŸ–¥ï¸ æ£€æŸ¥GPUçŠ¶æ€..."
nvidia-smi

# è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0
export PYTHONPATH="${PYTHONPATH}:$(pwd)/showui_core"

# è®­ç»ƒå‚æ•°
TRAIN_ARGS="

    --model_id showlab/ShowUI-2B \
    --local_weight \
    --local_weight_dir /models \
    --precision bf16 \

    --use_qlora \
    --load_in_4bit \
    --lora_r 16 \
    --lora_alpha 32 \
    --lora_dropout 0.1 \
    --lora_target_modules qkv_proj \
    --dataset_dir ./data \
    --train_dataset custom \
    --train_json metadata.json \
    --val_dataset custom \
    --val_json metadata.json \
    --batch_size 1 \
    --grad_accumulation_steps 8 \
    --lr 2e-4 \
    --warmup_steps 100 \
    --epochs 3 \
    --steps_per_epoch 500 \
    --gradient_checkpointing \
    --max_visual_tokens 1024 \
    --model_max_length 4096 \
    --log_base_dir ./logs \
    --exp_id ${EXP_ID} \
    --print_freq 10 \
    --workers 4 \
    --tune_visual_encoder false \
    --freeze_lm_embed
"

echo "ğŸƒ å¼€å§‹è®­ç»ƒ..."
cd showui_core

# ä½¿ç”¨tmuxè¿è¡Œè®­ç»ƒï¼ˆå¯é€‰ï¼Œä¾¿äºåå°è¿è¡Œï¼‰
if command -v tmux &> /dev/null; then
    echo "ğŸ“º åœ¨tmuxä¼šè¯ä¸­è¿è¡Œè®­ç»ƒ..."
    tmux new-session -d -s "showui_training_${TIMESTAMP}" \
        "python train.py ${TRAIN_ARGS}; read -p 'Training finished. Press enter to exit...'"
    echo "âœ… è®­ç»ƒå·²åœ¨tmuxä¼šè¯ 'showui_training_${TIMESTAMP}' ä¸­å¯åŠ¨"
    echo "ğŸ“‹ ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹è®­ç»ƒè¿›åº¦:"
    echo "   tmux attach -t showui_training_${TIMESTAMP}"
else
    echo "ğŸ”„ ç›´æ¥è¿è¡Œè®­ç»ƒ..."
    python train.py ${TRAIN_ARGS}
fi

echo "ğŸ‰ è®­ç»ƒè„šæœ¬æ‰§è¡Œå®Œæˆï¼"