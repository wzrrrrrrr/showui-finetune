# ShowUI-2B å¾®è°ƒè®­ç»ƒ

åŸºäºShowUI-2Bæ¨¡å‹çš„é«˜æ•ˆå¾®è°ƒè®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒQLoRA 4bité‡åŒ–å¾®è°ƒã€‚

## ğŸ–¥ï¸ ç¯å¢ƒè¦æ±‚

- **GPU**: NVIDIA GPU (æ¨èA10/V100/A100)
- **æ˜¾å­˜**: 16GB+ (æ¨è24GB+)
- **ç³»ç»Ÿ**: Linux (Ubuntu 18.04+/CentOS 7+)
- **CUDA**: 11.8+
- **Python**: 3.8+

## ğŸ”§ æŠ€æœ¯ç‰¹æ€§

- âœ… **QLoRAå¾®è°ƒ**: 4bité‡åŒ–ï¼Œå¤§å¹…é™ä½æ˜¾å­˜éœ€æ±‚
- âœ… **peftå…¼å®¹**: å®Œç¾å…¼å®¹peftå’Œbitsandbytes
- âœ… **æ ‡å‡†PyTorch**: ç§»é™¤DeepSpeedï¼Œé¿å…å…¼å®¹æ€§é—®é¢˜
- âœ… **æ··åˆç²¾åº¦**: æ”¯æŒBF16/FP16è®­ç»ƒ
- âœ… **æ¢¯åº¦ç´¯ç§¯**: æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡è®­ç»ƒæ•ˆæœ

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <your-repo>
cd showui-finetune

# 2. è¿è¡Œè‡ªåŠ¨åŒ–ç¯å¢ƒè®¾ç½®
chmod +x setup_env.sh
./setup_env.sh

# æˆ–æ‰‹åŠ¨å®‰è£…
python -m venv showui_env
source showui_env/bin/activate
pip install -r requirements.txt
```

### 2. æ¨¡å‹å‡†å¤‡

ç¡®ä¿ShowUI-2Bæ¨¡å‹åœ¨ `./models/ShowUI-2B/` ç›®å½•ä¸‹ï¼š

```bash
ls ./models/ShowUI-2B/
# åº”è¯¥åŒ…å«ï¼š
# - config.json
# - model.safetensors.index.json
# - model-*.safetensors
# - tokenizer.json
# - ç­‰æ–‡ä»¶
```

### 3. æ•°æ®å‡†å¤‡

ç¡®ä¿è®­ç»ƒæ•°æ®åœ¨ `./data/my_dataset/` ç›®å½•ä¸‹ï¼š

```bash
ls ./data/my_dataset/
# åº”è¯¥åŒ…å«ï¼š
# - metadata.json  (è®­ç»ƒæ•°æ®æ ‡æ³¨)
# - images/        (å›¾ç‰‡æ–‡ä»¶å¤¹)
```

### 4. å¼€å§‹è®­ç»ƒ

```bash
# ç»™è„šæœ¬æ‰§è¡Œæƒé™
chmod +x run_training.sh

# å¼€å§‹è®­ç»ƒ
./run_training.sh
```

## âš™ï¸ é…ç½®è¯´æ˜

### è®­ç»ƒå‚æ•°

ä¸»è¦è®­ç»ƒå‚æ•°åœ¨ `run_training.sh` ä¸­ï¼š

```bash
--model_id showlab/ShowUI-2B          # æ¨¡å‹ID
--local_weight_dir ./models           # æœ¬åœ°æ¨¡å‹è·¯å¾„
--precision bf16                      # ç²¾åº¦ (bf16/fp16/fp32)
--use_qlora                          # ä½¿ç”¨QLoRA
--load_in_4bit                       # 4bité‡åŒ–
--lora_r 16                          # LoRA rank
--lora_alpha 32                      # LoRA alpha
--batch_size 1                       # æ‰¹æ¬¡å¤§å°
--grad_accumulation_steps 8          # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
--lr 2e-4                           # å­¦ä¹ ç‡
--epochs 3                          # è®­ç»ƒè½®æ•°
--max_steps 1000                    # æœ€å¤§æ­¥æ•°
```

### è®­ç»ƒé…ç½®

æ ‡å‡†PyTorchè®­ç»ƒé…ç½®ï¼š

- **QLoRA**: 4bité‡åŒ–å¾®è°ƒ
- **BF16**: æ··åˆç²¾åº¦è®­ç»ƒ
- **æ¢¯åº¦ç´¯ç§¯**: æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡è®­ç»ƒ
- **å­¦ä¹ ç‡è°ƒåº¦**: çº¿æ€§warmup

## ğŸ“Š ç›‘æ§è®­ç»ƒ

### 1. ç»ˆç«¯è¾“å‡º

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ˜¾ç¤ºï¼š
- æŸå¤±å€¼å˜åŒ–
- è®­ç»ƒæ­¥æ•°
- GPUå†…å­˜ä½¿ç”¨
- è®­ç»ƒé€Ÿåº¦

### 2. æ—¥å¿—æ–‡ä»¶

è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨ `./logs/showui_YYYYMMDD_HHMMSS/`

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   ```bash
   # å‡å°‘æ‰¹æ¬¡å¤§å°
   --batch_size 1
   --grad_accumulation_steps 4
   ```

2. **CUDAç¯å¢ƒé—®é¢˜**
   ```bash
   # æ£€æŸ¥CUDAç¯å¢ƒ
   nvidia-smi
   nvcc --version
   ```

3. **æ¨¡å‹åŠ è½½å¤±è´¥**
   ```bash
   # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
   ls -la ./models/ShowUI-2B/
   ```

4. **ä¾èµ–å®‰è£…å¤±è´¥**
   ```bash
   # ä½¿ç”¨å›½å†…é•œåƒ
   pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt
   ```

### æ€§èƒ½ä¼˜åŒ–

1. **å¯ç”¨Flash Attention**
   ```bash
   pip install flash-attn --no-build-isolation
   ```

2. **è°ƒæ•´æ‰¹æ¬¡å¤§å°**
   - A10 24GB: batch_size=1, grad_accumulation_steps=8
   - æ›´å¤§GPU: å¯ä»¥å¢åŠ batch_size

3. **ä½¿ç”¨æ··åˆç²¾åº¦**
   ```bash
   --precision bf16  # æ¨è
   --precision fp16  # å¤‡é€‰
   ```

## ğŸ“ˆ è®­ç»ƒç»“æœ

è®­ç»ƒå®Œæˆåï¼š

åœ¨ `./logs/showui_YYYYMMDD_HHMMSS/` ç›®å½•ä¸‹åŒ…å«ï¼š

- **adapter_model.safetensors**: LoRAé€‚é…å™¨æƒé‡
- **adapter_config.json**: LoRAé…ç½®æ–‡ä»¶
- **README.md**: è®­ç»ƒä¿¡æ¯è¯´æ˜

## ğŸ¯ ä¸‹ä¸€æ­¥

1. **æ¨¡å‹æ¨ç†**: ä½¿ç”¨è®­ç»ƒå¥½çš„LoRAæƒé‡è¿›è¡Œæ¨ç†
2. **æ•ˆæœè¯„ä¼°**: åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
3. **å‚æ•°è°ƒä¼˜**: æ ¹æ®ç»“æœè°ƒæ•´è¶…å‚æ•°
4. **æ•°æ®æ‰©å……**: æ·»åŠ æ›´å¤šè®­ç»ƒæ•°æ®

## ğŸ“ æ”¯æŒ

å¦‚é‡é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. GPUé©±åŠ¨å’ŒCUDAç‰ˆæœ¬
2. Pythonç¯å¢ƒå’Œä¾èµ–ç‰ˆæœ¬
3. æ¨¡å‹å’Œæ•°æ®æ–‡ä»¶å®Œæ•´æ€§
4. ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
